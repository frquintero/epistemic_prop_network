# LLM Models Configuration Guide

## Overview

This document provides detailed information about the available Large Language Models (LLMs) on Groq that can be used in the Epistemological Propagation Network (EPN). Each model has specific characteristics, pricing, performance metrics, and optimal use cases for different EPN layers.

## Available Models

### 1. OpenAI GPT-OSS-120B (`openai/gpt-oss-120b`)

**Status**: Production Model  
**Provider**: OpenAI  
**Token Speed**: ~500 TPS  

#### GPT-OSS-120B Specifications

- **Context Window**: 131,072 tokens
- **Max Output Tokens**: 65,536
- **Architecture**: Mixture-of-Experts (MoE) with 120B total parameters
- **Active Parameters**: ~37B per forward pass
- **Quantization**: Groq TruePoint Numerics

... (rest of file moved)
